{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22f503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from numpy import * \n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9898a",
   "metadata": {},
   "source": [
    "### 若要測試單一個，請以以下方式引入單一資料集\n",
    "<span id=\"singleRunHead\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137ab690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_data = '../datasets/'\n",
    "# DATASET_CSV_NAME = '1_zoo.csv'\n",
    "# DATASET_NAME = 'zoo'\n",
    "# dir_train_test_data = f'../train_test_datasets/{DATASET_NAME}'\n",
    "# train_data_loc = os.path.join(dir_data, DATASET_CSV_NAME)\n",
    "# print('Path of read in data: %s' % (train_data_loc))\n",
    "# data = pd.read_csv(train_data_loc)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7a61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188cb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_1_data_loc = os.path.join(dir_train_test_data, 'train_1.csv')\n",
    "# train_1 = pd.read_csv(train_1_data_loc)\n",
    "# train_2_data_loc = os.path.join(dir_train_test_data, 'train_2.csv')\n",
    "# train_2 = pd.read_csv(train_2_data_loc)\n",
    "# train_3_data_loc = os.path.join(dir_train_test_data, 'train_3.csv')\n",
    "# train_3 = pd.read_csv(train_3_data_loc)\n",
    "# train_4_data_loc = os.path.join(dir_train_test_data, 'train_4.csv')\n",
    "# train_4 = pd.read_csv(train_4_data_loc)\n",
    "# train_5_data_loc = os.path.join(dir_train_test_data, 'train_5.csv')\n",
    "# train_5 = pd.read_csv(train_5_data_loc)\n",
    "# test_1_data_loc = os.path.join(dir_train_test_data, 'test_1.csv')\n",
    "# test_1 = pd.read_csv(test_1_data_loc)\n",
    "# test_2_data_loc = os.path.join(dir_train_test_data, 'test_2.csv')\n",
    "# test_2 = pd.read_csv(test_2_data_loc)\n",
    "# test_3_data_loc = os.path.join(dir_train_test_data, 'test_3.csv')\n",
    "# test_3 = pd.read_csv(test_3_data_loc)\n",
    "# test_4_data_loc = os.path.join(dir_train_test_data, 'test_4.csv')\n",
    "# test_4 = pd.read_csv(test_4_data_loc)\n",
    "# test_5_data_loc = os.path.join(dir_train_test_data, 'test_5.csv')\n",
    "# test_5 = pd.read_csv(test_5_data_loc)\n",
    "# del train_1['numbers']\n",
    "# del train_2['numbers']\n",
    "# del train_3['numbers']\n",
    "# del train_4['numbers']\n",
    "# del train_5['numbers']\n",
    "# del test_1['numbers']\n",
    "# del test_2['numbers']\n",
    "# del test_3['numbers']\n",
    "# del test_4['numbers']\n",
    "# del test_5['numbers']\n",
    "# training_Data = []\n",
    "# training_Data.append(train_1)\n",
    "# training_Data.append(train_2)\n",
    "# training_Data.append(train_3)\n",
    "# training_Data.append(train_4)\n",
    "# training_Data.append(train_5)\n",
    "# testing_Data = []\n",
    "# testing_Data.append(test_1)\n",
    "# testing_Data.append(test_2)\n",
    "# testing_Data.append(test_3)\n",
    "# testing_Data.append(test_4)\n",
    "# testing_Data.append(test_5)\n",
    "# training_Data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410a7be",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b73397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f3b40",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba83bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='rbf', probability=True, decision_function_shape='ovr', random_state=42) ## classifier\n",
    "knn = KNeighborsClassifier()\n",
    "# svm = LinearSVC(multi_class='crammer_singer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130dd4fb",
   "metadata": {},
   "source": [
    "### Datasets tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1843a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\n",
    "#     'Landsat',\n",
    "#     'soybean',\n",
    "#     'waveform',\n",
    "#     'Splice',\n",
    "#     'urban_land_cover','SCADI', \n",
    "#     'lung_discrete',\n",
    "#     'CNAE-9',\n",
    "#     'oh15','lung',\n",
    "#     'TOX_171',\n",
    "#     'orlraws10P',\n",
    "#     'CLL_SUB_111',\n",
    "    'CARCINOM',\n",
    "    'GLIOMA',\n",
    "    'AllBooks_baseline_DTM_Labelled'\n",
    "]\n",
    "    \n",
    "DATASETS_CSV = [\n",
    "#     '2_Landsat',\n",
    "#     '3_soybean', \n",
    "#     '4_waveform',\n",
    "#     '5_Splice',\n",
    "#     '6_urban_land_cover',\n",
    "#     '7_SCADI',\n",
    "#     '9_lung_discrete',\n",
    "#     '11_CNAE-9',\n",
    "#     '12_oh15',\n",
    "#     '13_lung',\n",
    "#     '14_TOX_171',\n",
    "#     '15_orlraws10P',\n",
    "#     '16_CLL_SUB_111',\n",
    "    'CARCINOM',\n",
    "    'GLIOMA',\n",
    "    'AllBooks_baseline_DTM_Labelled'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92bf6aa",
   "metadata": {},
   "source": [
    "### Feature Selection Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551e458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_embedded(train_data, test_data, data_temp, embedded_algo):\n",
    "    \n",
    "    data_ova = data_temp.copy()\n",
    "    data_forXGBoost = data_temp.copy()\n",
    "    del data_ova['class']\n",
    "        \n",
    "    data_ova = data_temp.copy()\n",
    "    \n",
    "    mms = pd.DataFrame(data=data_ova.drop(['class'], axis=1))\n",
    "    data_mxs = MinMaxScaler().fit_transform(mms)\n",
    "    data_mxs = pd.DataFrame(data=data_mxs, columns=data_ova.drop(['class'], axis=1).columns)\n",
    "    data_mxs['class'] = data_ova['class']\n",
    "    \n",
    "#      del data_ova['class']\n",
    "    del data_mxs['class']\n",
    "    try:\n",
    "        if(embedded_algo == 'Lasso'):\n",
    "            reg = LassoCV(random_state=2)\n",
    "            reg.fit(data_mxs, data_temp['class'])\n",
    "        elif(embedded_algo == 'Ridge'):\n",
    "            reg = RidgeCV()\n",
    "            reg.fit(data_mxs, data_temp['class'])\n",
    "        elif(embedded_algo == 'RandomForest'):\n",
    "            reg = RandomForestClassifier(n_estimators=100, random_state=2)\n",
    "            reg.fit(data_mxs, data_temp['class'])\n",
    "        elif(embedded_algo == 'XGBoost'):\n",
    "            reg = XGBClassifier()\n",
    "            for i in range(len(data_temp)):\n",
    "                data_forXGBoost['class'][i] = int(data_forXGBoost['class'][i])-1\n",
    "            reg.fit(data_mxs, data_forXGBoost['class'])\n",
    "            \n",
    "        \n",
    "        data_mxs = data_mxs.loc[:, data_mxs.columns != 'class']\n",
    "        if(embedded_algo == 'RandomForest' or embedded_algo == 'XGBoost'):\n",
    "            importances = reg.feature_importances_\n",
    "            print(importances)\n",
    "            keep_cols = [feature for feature, weight in zip (data_mxs.columns, importances) if weight != 0] \n",
    "        elif(embedded_algo == 'Lasso' or embedded_algo == 'Ridge'):\n",
    "            keep_cols = [feature for feature, weight in zip (data_mxs.columns, reg.coef_) if weight != 0] \n",
    "    except:\n",
    "        print(\"something wrong\")\n",
    "        keep_cols = []\n",
    "    return keep_cols, len(keep_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91450c5c",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e22007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_clean(train_data, test_data, choosedFeature_AfterAction):\n",
    "    temp = train_data.copy()\n",
    "    del temp['class']\n",
    "    temp_selected= temp[choosedFeature_AfterAction]\n",
    "    x_train = temp_selected.sort_index(axis=1)\n",
    "#     print(x_train) #80筆資料\n",
    "\n",
    "    #把測試集手動取出與訓練集相同維度的所有資料\n",
    "    temp_test = test_data.copy() #x_test\n",
    "    del temp_test['class']\n",
    "    temp_test_selected = temp_test[choosedFeature_AfterAction]\n",
    "    x_test = temp_test_selected.sort_index(axis=1)\n",
    "#     print(x_test)\n",
    "\n",
    "    y_train = train_data['class']\n",
    "    y_test = test_data['class']\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "def train_model(x_train, x_test, y_train, y_test, classifier):\n",
    "    ## train model\n",
    "#     print(x_train)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    predicted = classifier.predict(x_test) # 預測的答案\n",
    "    \n",
    "#     print(predicted)\n",
    "    '''-------------'''\n",
    "#     predict_proba = classifier.predict_proba(x_test)\n",
    "#     predict_proba = OneHotEncoder().fit_transform(predicted.reshape(-1,1)).toarray()\n",
    "#     predict_proba = list(predict_proba)\n",
    "\n",
    "#     not_predicted = []\n",
    "#     for i in range(len(arange(1,7))):\n",
    "#         if(i+1 not in predicted):\n",
    "#             not_predicted.append(i+1)\n",
    "# #     print(not_predicted)\n",
    "#     if(not_predicted):\n",
    "#         for i in range(len(not_predicted)):\n",
    "#             for j in range(len(predict_proba)):\n",
    "#                 predict_proba[j] = insert(predict_proba[j], not_predicted[i]-1, 0.)\n",
    "#     print(predict_proba)\n",
    "    '''-------------'''\n",
    "\n",
    "    '''-------------'''\n",
    "    lb = LabelBinarizer().fit(y_test)\n",
    "    y_test_ = lb.transform(y_test)\n",
    "    predict_proba = lb.transform(predicted)\n",
    "    '''-------------'''\n",
    "\n",
    "    y_test = array(list(y_test))\n",
    "    predicted = array(list(predicted))\n",
    "    y_train = array(list(y_train))\n",
    "    \n",
    "    # accuracy_train = svm.score(x_train, y_train) #x_train, y_train\n",
    "    # print(accuracy_train)\n",
    "#     rocaucscore = roc_auc_score(y_test_, predict_proba, multi_class='ovo',labels=arange(1,7), average='macro')\n",
    "    rocaucscore = roc_auc_score(y_test_, predict_proba, average='macro')\n",
    "\n",
    "    \n",
    "    acc_scikit = accuracy_score(y_test, predicted)\n",
    "#     accuracy_test = classifier.score(x_test, y_test) #x_test, y_test\n",
    "    f1score = f1_score(y_test, predicted, average='macro')\n",
    "\n",
    "    return acc_scikit, rocaucscore, f1score\n",
    "\n",
    "def train_test_baseline(train_data, test_data):\n",
    "    temp = train_data.copy()\n",
    "    del temp['class']\n",
    "    x_train = temp\n",
    "    \n",
    "    temp_test = test_data.copy()\n",
    "    del temp_test['class']\n",
    "    x_test = temp_test\n",
    "    \n",
    "    y_train = train_data['class']\n",
    "    y_test = test_data['class']\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a992c",
   "metadata": {},
   "source": [
    "### 以下方式為跑結果，分為統整跑(一次跑全部)跟個別跑(跑單一資料集的單一演算法)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61bdb1",
   "metadata": {},
   "source": [
    "### 1. 群體測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd377d39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = svm\n",
    "# classifier = knn\n",
    "\n",
    "\n",
    "# WRAPPER_ALGO = ['GA', 'PSO', 'WOA', 'GWO', 'HHO']\n",
    "EMBEDDED_ALGO = ['Lasso', 'Ridge', 'RandomForest', 'XGBoost']\n",
    "\n",
    "for z in range(len(EMBEDDED_ALGO)):\n",
    "    print(f'------------------{EMBEDDED_ALGO[z]}-----------------')\n",
    "    rocauc_container = []\n",
    "    f1score_container = []\n",
    "    acc_scikit_con = []\n",
    "    SUM_OF_COLUMNS = 0\n",
    "    len_of_columns = 0\n",
    "    for i in range(5):     \n",
    "        '''Wrapper!!!!'''\n",
    "        AfterFeatureSelection, len_of_columns = fs_embedded(training_Data[i], testing_Data[i], training_Data[i], EMBEDDED_ALGO[z])\n",
    "        print(AfterFeatureSelection)\n",
    "        x_train, x_test, y_train, y_test = train_test_clean(training_Data[i], testing_Data[i], AfterFeatureSelection)\n",
    "        SUM_OF_COLUMNS = SUM_OF_COLUMNS + len_of_columns\n",
    "        acc_scikit, rocaucs, f1score = train_model(x_train, x_test, y_train, y_test, classifier)\n",
    "        acc_scikit_con.append(acc_scikit)\n",
    "    #     accuracy_container.append(accuracy)\n",
    "        rocauc_container.append(rocaucs)\n",
    "        f1score_container.append(f1score)\n",
    "        print(f'accuracy of fold {i+1}: {acc_scikit}')\n",
    "        print(f'rocaucs of fold {i+1}: {rocaucs}')\n",
    "    \n",
    "    avg_acc_scikit = sum(acc_scikit_con)/5\n",
    "    # avg_acc = sum(accuracy_container)/5\n",
    "    avg_rocauc = sum(rocauc_container)/5\n",
    "    avg_f1score = sum(f1score_container)/5\n",
    "    print('--------Baseline2 Wrapper--------')\n",
    "    # print(f'avg_acc: {avg_acc}')\n",
    "    print(f'avg_acc_scikit: {avg_acc_scikit}')\n",
    "    print(f'avg_rocaucscore: {avg_rocauc}')\n",
    "    print(f'avg_f1score: {avg_f1score}')\n",
    "    print(f'avg_len: {SUM_OF_COLUMNS/5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9edb5d",
   "metadata": {},
   "source": [
    "### 2. 統整跑需要先做讀寫檔案操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f50f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFiles_Decom_UorI(STORE_PATH, DECOMPOSITION_TYPE, UorI, foldTurn, choosedFeature, f_len,FS_METHOD):\n",
    "    try:\n",
    "        file_U = open(STORE_PATH + f'/{DECOMPOSITION_TYPE}/{UorI}/{FS_METHOD}_folds{foldTurn+1}.txt','w')\n",
    "    except:\n",
    "        os.makedirs(STORE_PATH + f'/{DECOMPOSITION_TYPE}/{UorI}')\n",
    "        file_U = open(STORE_PATH + f'/{DECOMPOSITION_TYPE}/{UorI}/{FS_METHOD}_folds{foldTurn+1}.txt','w')\n",
    "    choosedFeature = sorted(choosedFeature)\n",
    "    for item in choosedFeature:\n",
    "        file_U.write(item+\"\\n\")\n",
    "    file_U.write(str(f_len)+\"\\n\")\n",
    "    file_U.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a9819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLines_UorI(STORE_PATH, DECOMPOSITION_TYPE, UorI, foldTurn,FS_METHOD):\n",
    "    try:\n",
    "        file1 = open(STORE_PATH + f'{DECOMPOSITION_TYPE}/{UorI}/{FS_METHOD}_folds{foldTurn+1}.txt', 'r')\n",
    "        Lines = file1.readlines()\n",
    "        choosedFeature = []\n",
    "        for line in Lines:\n",
    "            choosedFeature.append(line.strip())\n",
    "        choosedFeature = choosedFeature[:-1]\n",
    "        fs_len = Lines[-1]\n",
    "        file1.close()\n",
    "        return choosedFeature, fs_len\n",
    "    except:\n",
    "        return [], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2966f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_baseline = pd.DataFrame(columns=['datasetName', 'algoName','acc_u','auc_u','f1_u', 'len', 'spend_time','reductionRate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4f930",
   "metadata": {},
   "source": [
    "### Embedded 統整跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc06fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of read in data: ../datasets/CARCINOM.csv\n",
      "------------------Lasso-----------------\n",
      "------------------Ridge-----------------\n",
      "------------------RandomForest-----------------\n",
      "[0.         0.         0.         ... 0.00031917 0.         0.        ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      " 8.11030008e-05 0.00000000e+00]\n",
      "[0.         0.00070144 0.00022391 ... 0.         0.00010814 0.        ]\n",
      "[0.         0.         0.         ... 0.00134471 0.         0.        ]\n",
      "------------------XGBoost-----------------\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.00329664 0.         0.         ... 0.         0.         0.        ]\n",
      "[0.00170978 0.         0.         ... 0.         0.         0.        ]\n",
      "accuracy of fold 1: 0.7631578947368421\n",
      "rocaucs of fold 1: 0.8384771825396825\n",
      "accuracy of fold 2: 0.9117647058823529\n",
      "rocaucs of fold 2: 0.8893841431556949\n",
      "accuracy of fold 3: 0.8235294117647058\n",
      "rocaucs of fold 3: 0.8528637669801463\n",
      "accuracy of fold 4: 0.8823529411764706\n",
      "rocaucs of fold 4: 0.9240334378265413\n",
      "accuracy of fold 5: 0.8823529411764706\n",
      "rocaucs of fold 5: 0.9014072875585669\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.8526315789473685\n",
      "avg_rocaucscore: 0.8812331636121264\n",
      "avg_f1score: 0.752828181919091\n",
      "avg_len: 74.6\n",
      "accuracy of fold 1: 0.8421052631578947\n",
      "rocaucs of fold 1: 0.8984920634920635\n",
      "accuracy of fold 2: 0.8529411764705882\n",
      "rocaucs of fold 2: 0.8847894967472277\n",
      "accuracy of fold 3: 0.8529411764705882\n",
      "rocaucs of fold 3: 0.8998857105538142\n",
      "accuracy of fold 4: 0.9117647058823529\n",
      "rocaucs of fold 4: 0.9483281086729364\n",
      "accuracy of fold 5: 0.9117647058823529\n",
      "rocaucs of fold 5: 0.9119644723093\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.8743034055727554\n",
      "avg_rocaucscore: 0.9086919703550684\n",
      "avg_f1score: 0.8158625213170669\n",
      "avg_len: 9180.4\n",
      "accuracy of fold 1: 0.8947368421052632\n",
      "rocaucs of fold 1: 0.9415873015873016\n",
      "accuracy of fold 2: 0.9705882352941176\n",
      "rocaucs of fold 2: 0.9758064516129032\n",
      "accuracy of fold 3: 0.9117647058823529\n",
      "rocaucs of fold 3: 0.9408534735564769\n",
      "accuracy of fold 4: 0.9117647058823529\n",
      "rocaucs of fold 4: 0.9483281086729364\n",
      "accuracy of fold 5: 0.9411764705882353\n",
      "rocaucs of fold 5: 0.9286833855799372\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.9260061919504643\n",
      "avg_rocaucscore: 0.9470517442019112\n",
      "avg_f1score: 0.8864764528400892\n",
      "avg_len: 1892.6\n",
      "accuracy of fold 1: 0.7894736842105263\n",
      "rocaucs of fold 1: 0.8632821300563235\n",
      "accuracy of fold 2: 0.8529411764705882\n",
      "rocaucs of fold 2: 0.8770114942528736\n",
      "accuracy of fold 3: 0.9705882352941176\n",
      "rocaucs of fold 3: 0.9893416927899686\n",
      "accuracy of fold 4: 0.9117647058823529\n",
      "rocaucs of fold 4: 0.9347928674958706\n",
      "accuracy of fold 5: 0.9705882352941176\n",
      "rocaucs of fold 5: 0.975705329153605\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.8990712074303404\n",
      "avg_rocaucscore: 0.9280267027497283\n",
      "avg_f1score: 0.8690629017447199\n",
      "avg_len: 117.2\n",
      "Path of read in data: ../datasets/GLIOMA.csv\n",
      "------------------Lasso-----------------\n",
      "------------------Ridge-----------------\n",
      "------------------RandomForest-----------------\n",
      "[0.00288833 0.         0.         ... 0.         0.         0.        ]\n",
      "[0.         0.         0.         ... 0.         0.         0.00327731]\n",
      "[0.         0.         0.         ... 0.         0.         0.00586755]\n",
      "[0.         0.         0.         ... 0.         0.         0.00357127]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "------------------XGBoost-----------------\n",
      "[0.01748051 0.         0.         ... 0.         0.         0.        ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.01069643 0.         0.         ... 0.         0.         0.        ]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0.         0.01134081 0.         ... 0.         0.         0.        ]\n",
      "accuracy of fold 1: 0.8\n",
      "rocaucs of fold 1: 0.8623511904761905\n",
      "accuracy of fold 2: 0.8\n",
      "rocaucs of fold 2: 0.8015873015873016\n",
      "accuracy of fold 3: 0.8\n",
      "rocaucs of fold 3: 0.7976190476190477\n",
      "accuracy of fold 4: 0.8\n",
      "rocaucs of fold 4: 0.8809523809523809\n",
      "accuracy of fold 5: 0.7\n",
      "rocaucs of fold 5: 0.8253968253968254\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.78\n",
      "avg_rocaucscore: 0.8335813492063492\n",
      "avg_f1score: 0.7159523809523808\n",
      "avg_len: 52.8\n",
      "accuracy of fold 1: 0.6\n",
      "rocaucs of fold 1: 0.7477678571428572\n",
      "accuracy of fold 2: 0.7\n",
      "rocaucs of fold 2: 0.746031746031746\n",
      "accuracy of fold 3: 0.8\n",
      "rocaucs of fold 3: 0.8809523809523809\n",
      "accuracy of fold 4: 0.8\n",
      "rocaucs of fold 4: 0.8809523809523809\n",
      "accuracy of fold 5: 0.6\n",
      "rocaucs of fold 5: 0.7658730158730158\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.7\n",
      "avg_rocaucscore: 0.8043154761904763\n",
      "avg_f1score: 0.6778571428571428\n",
      "avg_len: 4432.0\n",
      "accuracy of fold 1: 0.6\n",
      "rocaucs of fold 1: 0.7477678571428572\n",
      "accuracy of fold 2: 0.8\n",
      "rocaucs of fold 2: 0.8015873015873016\n",
      "accuracy of fold 3: 0.9\n",
      "rocaucs of fold 3: 0.9404761904761905\n",
      "accuracy of fold 4: 0.8\n",
      "rocaucs of fold 4: 0.7976190476190477\n",
      "accuracy of fold 5: 0.6\n",
      "rocaucs of fold 5: 0.7658730158730158\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.74\n",
      "avg_rocaucscore: 0.8106646825396826\n",
      "avg_f1score: 0.6669047619047619\n",
      "avg_len: 417.6\n",
      "accuracy of fold 1: 0.7\n",
      "rocaucs of fold 1: 0.828125\n",
      "accuracy of fold 2: 0.5\n",
      "rocaucs of fold 2: 0.626984126984127\n",
      "accuracy of fold 3: 0.8\n",
      "rocaucs of fold 3: 0.8809523809523809\n",
      "accuracy of fold 4: 0.7\n",
      "rocaucs of fold 4: 0.8253968253968254\n",
      "accuracy of fold 5: 0.5\n",
      "rocaucs of fold 5: 0.7063492063492063\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.64\n",
      "avg_rocaucscore: 0.7735615079365079\n",
      "avg_f1score: 0.6171428571428572\n",
      "avg_len: 44.6\n",
      "Path of read in data: ../datasets/AllBooks_baseline_DTM_Labelled.csv\n",
      "------------------Lasso-----------------\n",
      "------------------Ridge-----------------\n",
      "------------------RandomForest-----------------\n",
      "[0.00000000e+00 5.06948066e-03 3.75414774e-05 ... 1.00128057e-04\n",
      " 4.46080721e-05 7.69005069e-05]\n",
      "[1.28262455e-04 8.30306875e-03 3.05086733e-05 ... 2.71023865e-04\n",
      " 8.21652954e-05 0.00000000e+00]\n",
      "[0.00000000e+00 3.64433637e-03 0.00000000e+00 ... 7.00579319e-05\n",
      " 0.00000000e+00 9.21639845e-05]\n",
      "[0.00000000e+00 6.22641094e-03 0.00000000e+00 ... 0.00000000e+00\n",
      " 0.00000000e+00 6.05007503e-05]\n",
      "[7.56860636e-05 5.11790695e-03 8.94641725e-05 ... 2.72190195e-05\n",
      " 0.00000000e+00 4.08022242e-05]\n",
      "------------------XGBoost-----------------\n",
      "[0.         0.01675921 0.         ... 0.         0.         0.        ]\n",
      "[0.         0.02090678 0.         ... 0.         0.         0.        ]\n",
      "[0.        0.0192243 0.        ... 0.        0.        0.       ]\n",
      "[0.         0.02444082 0.         ... 0.         0.         0.        ]\n",
      "[0.         0.02370707 0.         ... 0.         0.         0.        ]\n",
      "accuracy of fold 1: 0.5901639344262295\n",
      "rocaucs of fold 1: 0.6690610022530701\n",
      "accuracy of fold 2: 0.5897435897435898\n",
      "rocaucs of fold 2: 0.6556900738364295\n",
      "accuracy of fold 3: 0.5384615384615384\n",
      "rocaucs of fold 3: 0.6670330801872182\n",
      "accuracy of fold 4: 0.5213675213675214\n",
      "rocaucs of fold 4: 0.6834636525188206\n",
      "accuracy of fold 5: 0.5555555555555556\n",
      "rocaucs of fold 5: 0.7453369269109433\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.5590584279108869\n",
      "avg_rocaucscore: 0.6841169471412962\n",
      "avg_f1score: 0.4387325564209247\n",
      "avg_len: 306.4\n",
      "accuracy of fold 1: 0.3524590163934426\n",
      "rocaucs of fold 1: 0.5599480048469019\n",
      "accuracy of fold 2: 0.452991452991453\n",
      "rocaucs of fold 2: 0.6742460687628117\n",
      "accuracy of fold 3: 0.38461538461538464\n",
      "rocaucs of fold 3: 0.5779431526109837\n",
      "accuracy of fold 4: 0.37606837606837606\n",
      "rocaucs of fold 4: 0.5940618398754809\n",
      "accuracy of fold 5: 0.39316239316239315\n",
      "rocaucs of fold 5: 0.6617830235916637\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.3918593246462099\n",
      "avg_rocaucscore: 0.6135964179375684\n",
      "avg_f1score: 0.3030818296806358\n",
      "avg_len: 7407.8\n",
      "accuracy of fold 1: 0.39344262295081966\n",
      "rocaucs of fold 1: 0.5912267763370704\n",
      "accuracy of fold 2: 0.47863247863247865\n",
      "rocaucs of fold 2: 0.6900856697168165\n",
      "accuracy of fold 3: 0.4358974358974359\n",
      "rocaucs of fold 3: 0.6469126328502794\n",
      "accuracy of fold 4: 0.4017094017094017\n",
      "rocaucs of fold 4: 0.6031187911939961\n",
      "accuracy of fold 5: 0.38461538461538464\n",
      "rocaucs of fold 5: 0.6509388351894076\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.41885946476110414\n",
      "avg_rocaucscore: 0.636456541057514\n",
      "avg_f1score: 0.3555186233135016\n",
      "avg_len: 3745.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of fold 1: 0.5901639344262295\n",
      "rocaucs of fold 1: 0.6610194757499785\n",
      "accuracy of fold 2: 0.6581196581196581\n",
      "rocaucs of fold 2: 0.787249627162141\n",
      "accuracy of fold 3: 0.6239316239316239\n",
      "rocaucs of fold 3: 0.6808612721302076\n",
      "accuracy of fold 4: 0.5555555555555556\n",
      "rocaucs of fold 4: 0.710285971885654\n",
      "accuracy of fold 5: 0.5470085470085471\n",
      "rocaucs of fold 5: 0.729408899457349\n",
      "--------Baseline2 Embedded--------\n",
      "avg_acc_scikit: 0.5949558638083229\n",
      "avg_rocaucscore: 0.713765049277066\n",
      "avg_f1score: 0.4963688843342277\n",
      "avg_len: 289.0\n"
     ]
    }
   ],
   "source": [
    "classifier = knn\n",
    "CLASSIFIER_STRING = \"KNN\"\n",
    "EMBEDDED_ALGO = ['Lasso', 'Ridge', 'RandomForest', 'XGBoost']\n",
    "\n",
    "dir_data = '../datasets/'\n",
    "for qq in range(len(DATASETS)):\n",
    "    DATASET_CSV_NAME = f'{DATASETS_CSV[qq]}.csv'\n",
    "    DATASET_NAME = f'{DATASETS[qq]}'\n",
    "    dir_train_test_data = f'../train_test_datasets/{DATASET_NAME}'\n",
    "\n",
    "    train_data_loc = os.path.join(dir_data, DATASET_CSV_NAME)\n",
    "    print('Path of read in data: %s' % (train_data_loc))\n",
    "    data = pd.read_csv(train_data_loc)\n",
    "    # data\n",
    "    \n",
    "    CLASS_AMOUNT = data['class'].value_counts().size\n",
    "    FEATURE_AMOUNT = len(data.columns)-2\n",
    "    # CLASS_AMOUNT\n",
    "\n",
    "    train_1_data_loc = os.path.join(dir_train_test_data, 'train_1.csv')\n",
    "    train_1 = pd.read_csv(train_1_data_loc)\n",
    "    train_2_data_loc = os.path.join(dir_train_test_data, 'train_2.csv')\n",
    "    train_2 = pd.read_csv(train_2_data_loc)\n",
    "    train_3_data_loc = os.path.join(dir_train_test_data, 'train_3.csv')\n",
    "    train_3 = pd.read_csv(train_3_data_loc)\n",
    "    train_4_data_loc = os.path.join(dir_train_test_data, 'train_4.csv')\n",
    "    train_4 = pd.read_csv(train_4_data_loc)\n",
    "    train_5_data_loc = os.path.join(dir_train_test_data, 'train_5.csv')\n",
    "    train_5 = pd.read_csv(train_5_data_loc)\n",
    "    test_1_data_loc = os.path.join(dir_train_test_data, 'test_1.csv')\n",
    "    test_1 = pd.read_csv(test_1_data_loc)\n",
    "    test_2_data_loc = os.path.join(dir_train_test_data, 'test_2.csv')\n",
    "    test_2 = pd.read_csv(test_2_data_loc)\n",
    "    test_3_data_loc = os.path.join(dir_train_test_data, 'test_3.csv')\n",
    "    test_3 = pd.read_csv(test_3_data_loc)\n",
    "    test_4_data_loc = os.path.join(dir_train_test_data, 'test_4.csv')\n",
    "    test_4 = pd.read_csv(test_4_data_loc)\n",
    "    test_5_data_loc = os.path.join(dir_train_test_data, 'test_5.csv')\n",
    "    test_5 = pd.read_csv(test_5_data_loc)\n",
    "    del train_1['numbers']\n",
    "    del train_2['numbers']\n",
    "    del train_3['numbers']\n",
    "    del train_4['numbers']\n",
    "    del train_5['numbers']\n",
    "    del test_1['numbers']\n",
    "    del test_2['numbers']\n",
    "    del test_3['numbers']\n",
    "    del test_4['numbers']\n",
    "    del test_5['numbers']\n",
    "    training_Data = []\n",
    "    training_Data.append(train_1)\n",
    "    training_Data.append(train_2)\n",
    "    training_Data.append(train_3)\n",
    "    training_Data.append(train_4)\n",
    "    training_Data.append(train_5)\n",
    "    testing_Data = []\n",
    "    testing_Data.append(test_1)\n",
    "    testing_Data.append(test_2)\n",
    "    testing_Data.append(test_3)\n",
    "    testing_Data.append(test_4)\n",
    "    testing_Data.append(test_5)\n",
    "    \n",
    "    spend_time = 0\n",
    "    for z in range(len(EMBEDDED_ALGO)):\n",
    "        print(f'------------------{EMBEDDED_ALGO[z]}-----------------')\n",
    "        STORE_PATH = f'./EMBEDDED_{EMBEDDED_ALGO[z]}/{DATASET_NAME}/'\n",
    "        for i in range(5):     \n",
    "            start_time = time.time()\n",
    "            AfterFeatureSelection, len_of_columns = fs_embedded(training_Data[i], testing_Data[i], training_Data[i], EMBEDDED_ALGO[z])\n",
    "    #         print(AfterFeatureSelection)\n",
    "            end_time = time.time()\n",
    "            spend_time += end_time - start_time\n",
    "            writeFiles_Decom_UorI(STORE_PATH, 'BASELINE', 'N', i, AfterFeatureSelection, len_of_columns, EMBEDDED_ALGO[z])\n",
    "        spend_time = spend_time//5\n",
    "    \n",
    "    for kk in range(len(EMBEDDED_ALGO)):\n",
    "        STORE_PATH = f'./EMBEDDED_{EMBEDDED_ALGO[kk]}/{DATASET_NAME}/'\n",
    "        rocauc_container = []\n",
    "        f1score_container = []\n",
    "        acc_scikit_con = []\n",
    "        SUM_OF_COLUMNS = 0\n",
    "        len_of_columns = 0\n",
    "        for i in range(5):\n",
    "            AfterFeatureSelection, len_of_columns = readLines_UorI(STORE_PATH, 'BASELINE', 'N', i, EMBEDDED_ALGO[kk])\n",
    "            if(AfterFeatureSelection  != []):\n",
    "                x_train, x_test, y_train, y_test = train_test_clean(training_Data[i], testing_Data[i], AfterFeatureSelection)\n",
    "                SUM_OF_COLUMNS = SUM_OF_COLUMNS + int(len_of_columns)\n",
    "                acc_scikit, rocaucs, f1score = train_model(x_train, x_test, y_train, y_test, classifier)\n",
    "                acc_scikit_con.append(acc_scikit)\n",
    "        #     accuracy_container.append(accuracy)\n",
    "                rocauc_container.append(rocaucs)\n",
    "                f1score_container.append(f1score)\n",
    "            else:\n",
    "                acc_scikit_con.append(0)\n",
    "                rocauc_container.append(0)\n",
    "                f1score_container.append(0)\n",
    "            print(f'accuracy of fold {i+1}: {acc_scikit}')\n",
    "            print(f'rocaucs of fold {i+1}: {rocaucs}')\n",
    "        \n",
    "        avg_acc_scikit = sum(acc_scikit_con)/5\n",
    "        # avg_acc = sum(accuracy_container)/5\n",
    "        avg_rocauc = sum(rocauc_container)/5\n",
    "        avg_f1score = sum(f1score_container)/5\n",
    "        print('--------Baseline2 Embedded--------')\n",
    "        # print(f'avg_acc: {avg_acc}')\n",
    "        print(f'avg_acc_scikit: {avg_acc_scikit}')\n",
    "        print(f'avg_rocaucscore: {avg_rocauc}')\n",
    "        print(f'avg_f1score: {avg_f1score}')\n",
    "        print(f'avg_len: {SUM_OF_COLUMNS/5}')\n",
    "    \n",
    "        t = pd.DataFrame([{'datasetName':DATASET_NAME,\n",
    "                     'algoName':EMBEDDED_ALGO[z],\n",
    "                     'acc_u':str(round(avg_acc_scikit,3)),\n",
    "                     'auc_u':str(round(avg_rocauc,3)),\n",
    "                     'f1_u':str(round(avg_f1score,3)),\n",
    "                     'len':str(round(SUM_OF_COLUMNS/5,3)),\n",
    "                     'spend_time':str(round(spend_time,3)),\n",
    "                     'reductionRate':str(round((SUM_OF_COLUMNS/5)/FEATURE_AMOUNT, 3))\n",
    "                    }])\n",
    "        result_baseline = pd.concat([result_baseline, t]).reset_index(drop=True).astype('string')\n",
    "\n",
    "    \n",
    "with pd.ExcelWriter(f'./result_excel_embedded/result_baseline_fs_embedded_{CLASSIFIER_STRING}_230917.xlsx') as writer:\n",
    "    result_baseline.to_excel(writer, sheet_name='baseline_svm_fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = knn\n",
    "CLASSIFIER_STRING = \"KNN\"\n",
    "EMBEDDED_ALGO = ['Lasso', 'Ridge', 'RandomForest', 'XGBoost']\n",
    "\n",
    "dir_data = '../datasets/'\n",
    "for qq in range(len(DATASETS)):\n",
    "    DATASET_CSV_NAME = f'{DATASETS_CSV[qq]}.csv'\n",
    "    DATASET_NAME = f'{DATASETS[qq]}'\n",
    "    dir_train_test_data = f'../train_test_datasets/{DATASET_NAME}'\n",
    "\n",
    "    train_data_loc = os.path.join(dir_data, DATASET_CSV_NAME)\n",
    "    print('Path of read in data: %s' % (train_data_loc))\n",
    "    data = pd.read_csv(train_data_loc)\n",
    "    # data\n",
    "    \n",
    "    CLASS_AMOUNT = data['class'].value_counts().size\n",
    "    FEATURE_AMOUNT = len(data.columns)-2\n",
    "    # CLASS_AMOUNT\n",
    "\n",
    "    train_1_data_loc = os.path.join(dir_train_test_data, 'train_1.csv')\n",
    "    train_1 = pd.read_csv(train_1_data_loc)\n",
    "    train_2_data_loc = os.path.join(dir_train_test_data, 'train_2.csv')\n",
    "    train_2 = pd.read_csv(train_2_data_loc)\n",
    "    train_3_data_loc = os.path.join(dir_train_test_data, 'train_3.csv')\n",
    "    train_3 = pd.read_csv(train_3_data_loc)\n",
    "    train_4_data_loc = os.path.join(dir_train_test_data, 'train_4.csv')\n",
    "    train_4 = pd.read_csv(train_4_data_loc)\n",
    "    train_5_data_loc = os.path.join(dir_train_test_data, 'train_5.csv')\n",
    "    train_5 = pd.read_csv(train_5_data_loc)\n",
    "    test_1_data_loc = os.path.join(dir_train_test_data, 'test_1.csv')\n",
    "    test_1 = pd.read_csv(test_1_data_loc)\n",
    "    test_2_data_loc = os.path.join(dir_train_test_data, 'test_2.csv')\n",
    "    test_2 = pd.read_csv(test_2_data_loc)\n",
    "    test_3_data_loc = os.path.join(dir_train_test_data, 'test_3.csv')\n",
    "    test_3 = pd.read_csv(test_3_data_loc)\n",
    "    test_4_data_loc = os.path.join(dir_train_test_data, 'test_4.csv')\n",
    "    test_4 = pd.read_csv(test_4_data_loc)\n",
    "    test_5_data_loc = os.path.join(dir_train_test_data, 'test_5.csv')\n",
    "    test_5 = pd.read_csv(test_5_data_loc)\n",
    "    del train_1['numbers']\n",
    "    del train_2['numbers']\n",
    "    del train_3['numbers']\n",
    "    del train_4['numbers']\n",
    "    del train_5['numbers']\n",
    "    del test_1['numbers']\n",
    "    del test_2['numbers']\n",
    "    del test_3['numbers']\n",
    "    del test_4['numbers']\n",
    "    del test_5['numbers']\n",
    "    training_Data = []\n",
    "    training_Data.append(train_1)\n",
    "    training_Data.append(train_2)\n",
    "    training_Data.append(train_3)\n",
    "    training_Data.append(train_4)\n",
    "    training_Data.append(train_5)\n",
    "    testing_Data = []\n",
    "    testing_Data.append(test_1)\n",
    "    testing_Data.append(test_2)\n",
    "    testing_Data.append(test_3)\n",
    "    testing_Data.append(test_4)\n",
    "    testing_Data.append(test_5)\n",
    "    \n",
    "    for kk in range(len(EMBEDDED_ALGO)):\n",
    "        STORE_PATH = f'./EMBEDDED_{EMBEDDED_ALGO[kk]}/{DATASET_NAME}/'\n",
    "        rocauc_container = []\n",
    "        f1score_container = []\n",
    "        acc_scikit_con = []\n",
    "        SUM_OF_COLUMNS = 0\n",
    "        len_of_columns = 0\n",
    "        for i in range(5):\n",
    "            AfterFeatureSelection, len_of_columns = readLines_UorI(STORE_PATH, 'BASELINE', 'N', i, EMBEDDED_ALGO[kk])\n",
    "            if(AfterFeatureSelection  != []):\n",
    "                x_train, x_test, y_train, y_test = train_test_clean(training_Data[i], testing_Data[i], AfterFeatureSelection)\n",
    "                SUM_OF_COLUMNS = SUM_OF_COLUMNS + int(len_of_columns)\n",
    "                acc_scikit, rocaucs, f1score = train_model(x_train, x_test, y_train, y_test, classifier)\n",
    "                acc_scikit_con.append(acc_scikit)\n",
    "        #     accuracy_container.append(accuracy)\n",
    "                rocauc_container.append(rocaucs)\n",
    "                f1score_container.append(f1score)\n",
    "            else:\n",
    "                acc_scikit_con.append(0)\n",
    "                rocauc_container.append(0)\n",
    "                f1score_container.append(0)\n",
    "            print(f'accuracy of fold {i+1}: {acc_scikit}')\n",
    "            print(f'rocaucs of fold {i+1}: {rocaucs}')\n",
    "        \n",
    "        avg_acc_scikit = sum(acc_scikit_con)/5\n",
    "        # avg_acc = sum(accuracy_container)/5\n",
    "        avg_rocauc = sum(rocauc_container)/5\n",
    "        avg_f1score = sum(f1score_container)/5\n",
    "        print('--------Baseline2 Embedded--------')\n",
    "        # print(f'avg_acc: {avg_acc}')\n",
    "        print(f'avg_acc_scikit: {avg_acc_scikit}')\n",
    "        print(f'avg_rocaucscore: {avg_rocauc}')\n",
    "        print(f'avg_f1score: {avg_f1score}')\n",
    "        print(f'avg_len: {SUM_OF_COLUMNS/5}')\n",
    "    \n",
    "        t = pd.DataFrame([{'datasetName':DATASET_NAME,\n",
    "                     'algoName':EMBEDDED_ALGO[z],\n",
    "                     'acc_u':str(round(avg_acc_scikit,3)),\n",
    "                     'auc_u':str(round(avg_rocauc,3)),\n",
    "                     'f1_u':str(round(avg_f1score,3)),\n",
    "                     'len':str(round(SUM_OF_COLUMNS/5,3)),\n",
    "                     'spend_time':str(round(spend_time,3)),\n",
    "                     'reductionRate':str(round((SUM_OF_COLUMNS/5)/FEATURE_AMOUNT, 3))\n",
    "                    }])\n",
    "        result_baseline = pd.concat([result_baseline, t]).reset_index(drop=True).astype('string')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7218369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'./result_excel_embedded/result_baseline_fs_embedded.xlsx') as writer:\n",
    "    result_baseline.to_excel(writer, sheet_name='baseline_svm_fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909bd6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
