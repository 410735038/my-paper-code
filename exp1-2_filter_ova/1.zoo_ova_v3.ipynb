{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e898db9f",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "364450ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b8d74c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "41bb26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "267c44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path of read in data: ../datasets/1_zoo.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15  A16  \\\n",
       "0   1   0   0   1   0   0   1   1   1    1    0    0    4    0    0    1   \n",
       "1   1   0   0   1   0   0   0   1   1    1    0    0    4    1    0    1   \n",
       "2   0   0   1   0   0   1   1   1   1    0    0    1    0    1    0    0   \n",
       "3   1   0   0   1   0   0   1   1   1    1    0    0    4    0    0    1   \n",
       "4   1   0   0   1   0   0   1   1   1    1    0    0    4    1    0    1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      4  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loc = os.path.join(dir_data, '1_zoo.csv')\n",
    "print('Path of read in data: %s' % (train_data_loc))\n",
    "data = pd.read_csv(train_data_loc)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a35448c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a2c3267c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    41\n",
       "2    20\n",
       "4    13\n",
       "7    10\n",
       "6     8\n",
       "3     5\n",
       "5     4\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check class 各自的筆數\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6e916347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8856d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['class']\n",
    "# target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e87d3",
   "metadata": {},
   "source": [
    "## Data Split  \n",
    "將資料分成 80% 20%，每個人都要當過測試的20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "e3eecd78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# part 1\n",
    "#train 0~79\n",
    "train_1 = data.head(int(data['class'].size*0.8))\n",
    "train_1 = train_1.reset_index(drop=True)\n",
    "#test 80~100\n",
    "test_1 = data.tail(int(data['class'].size*0.2)+1)\n",
    "test_1 = test_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5c7f32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2\n",
    "# train\n",
    "t1 = data.head(int(data['class'].size*0.6)) #0~59 \n",
    "t2 = data.tail(int(data['class'].size*0.2)+1) #80~100\n",
    "train_2 = pd.concat([t1,t2])\n",
    "train_2 = train_2.reset_index(drop=True)\n",
    "# test\n",
    "test_2 = data.iloc[int(data['class'].size*0.6):int(data['class'].size*0.8)] #60~79\n",
    "test_2 = test_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d1814844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3\n",
    "#train\n",
    "t1 = data.head(int(data['class'].size*0.4)) #0~39\n",
    "t2 = data.tail(int(data['class'].size*0.4)+1) #60~100\n",
    "train_3 = pd.concat([t1,t2])\n",
    "train_3 = train_3.reset_index(drop=True)\n",
    "# test\n",
    "test_3 = data.iloc[int(data['class'].size*0.4):int(data['class'].size*0.6)] #40~59\n",
    "test_3 = test_3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "741d9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 4\n",
    "#train\n",
    "t1 = data.head(int(data['class'].size*0.2)) #0~19\n",
    "t2 = data.tail(int(data['class'].size*0.6)+1) #40~100\n",
    "train_4 = pd.concat([t1,t2])\n",
    "train_4 = train_4.reset_index(drop=True)\n",
    "#test\n",
    "test_4 = data.iloc[int(data['class'].size*0.2):int(data['class'].size*0.4)] #20~39\n",
    "test_4 = test_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "527b7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 5\n",
    "#train\n",
    "train_5 = data.tail(int(data['class'].size*0.8)+1) #20~100\n",
    "train_5 = train_5.reset_index(drop=True)\n",
    "# test\n",
    "test_5 = data.head(int(data['class'].size*0.2)) #0~19\n",
    "test_5 = test_5.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "cb135d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Data = []\n",
    "training_Data.append(train_1)\n",
    "training_Data.append(train_2)\n",
    "training_Data.append(train_3)\n",
    "training_Data.append(train_4)\n",
    "training_Data.append(train_5)\n",
    "testing_Data = []\n",
    "testing_Data.append(test_1)\n",
    "testing_Data.append(test_2)\n",
    "testing_Data.append(test_3)\n",
    "testing_Data.append(test_4)\n",
    "testing_Data.append(test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2f6a5",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "82495b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args:\n",
    "    train_array: 訓練的資料，每個trainData要呼叫一次以執行 decomposition\n",
    "return:\n",
    "    data_temp: 進行decomposition後的資料集，會在最後加上 class_ova 的標籤\n",
    "'''\n",
    "def decomposition(train_array):\n",
    "    class_ova = [] ## ova label 佔存，每次迴圈插入進當次的 ova dataframe\n",
    "    data_temp = [] ## ova dataframe container，分別會有「是 i 與非 i 的 label」\n",
    "    for i in range(data['class'].value_counts().size):\n",
    "        data_temp.append(train_array.copy())\n",
    "        class_ova = []\n",
    "        for j in range(train_array[\"class\"].size):\n",
    "            if(data_temp[i][\"class\"][j] == i+1):\n",
    "                class_ova.append(1)\n",
    "            elif(data_temp[i][\"class\"][j] != i+1):\n",
    "                class_ova.append(2)\n",
    "        data_temp[i][str(\"class_ova_\")+str(i+1)] = class_ova\n",
    "    return data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e3b590a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_AfterDecomposition = decomposition(train_1)\n",
    "# data_AfterDecomposition = decomposition(train_2)\n",
    "# data_AfterDecomposition = decomposition(train_3)\n",
    "# data_AfterDecomposition = decomposition(train_4)\n",
    "# data_AfterDecomposition = decomposition(train_5)\n",
    "# data_AfterDecomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f73a0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一與非一\n",
    "# data_AfterDecomposition[0].loc[data_AfterDecomposition[0]['class_ova_1'] == 2].head()\n",
    "# 二與非二\n",
    "# data_temp[1].loc[data_temp[1]['class_ova_2'] == 2].head()\n",
    "# 三與非三\n",
    "# data_temp[2].loc[data_temp[2]['class_ova_3'] == 2].head()\n",
    "# 四與非四\n",
    "# data_temp[3].loc[data_temp[3]['class_ova_4'] == 2].head()\n",
    "# 五與非五\n",
    "# data_temp[4].loc[data_temp[4]['class_ova_5'] == 2].head()\n",
    "# 六與非六\n",
    "# data_temp[5].loc[data_temp[5]['class_ova_6'] == 2].head()\n",
    "# 七與非七\n",
    "# data_temp[6].loc[data_temp[6]['class_ova_7'] == 2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b603f77",
   "metadata": {},
   "source": [
    "## import fs + classfier Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "91c483fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(mutual_info_classif, percentile=50) ## fs- selector\n",
    "svm = SVC(kernel='linear', probability=True) ## classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a2100",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args:\n",
    "    cols_container: 用來裝每次 fs 後篩選出來的 feature 們\n",
    "    data_temp: 沒有特別意義，就是資料集\n",
    "return:\n",
    "    cols_container: 把 decomposition 後的資料集們個別進行 fs 後，篩出來的 f 裝在這個陣列內回傳\n",
    "'''\n",
    "def featureSelection(cols_container, data_temp):\n",
    "    ## fs\n",
    "    print(\"-------fs-------\")\n",
    "    for i in range(data['class'].value_counts().size):\n",
    "        data_ova = data_temp[i].copy()\n",
    "        del data_ova['class']\n",
    "        data_ova_no_label = data_ova.copy()\n",
    "        del data_ova_no_label[str('class_ova_')+str(i+1)]\n",
    "        x_reduced = selector.fit_transform(data_ova_no_label, data_ova[str('class_ova_')+str(i+1)])\n",
    "        # x_reduced.shape\n",
    "        cols = selector.get_support(indices=True)\n",
    "        selected_columns = data_ova_no_label.iloc[:,cols].columns.tolist()\n",
    "        cols_container.append(selected_columns)\n",
    "        print(i+1,'not ', i+1, ':',selected_columns)\n",
    "    return cols_container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c6eec",
   "metadata": {},
   "source": [
    "## Union and Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args:\n",
    "    cols_container: fs 後的 f 集合，將每個 decomposition 後的 f 集合進行聯集\n",
    "return:\n",
    "    list(C): 把聯集後的結果回傳\n",
    "'''\n",
    "def Union(cols_container):\n",
    "    ## fs - Union\n",
    "    print(\"-------fs-Union-------\")\n",
    "    union_temp = cols_container.copy()\n",
    "    A = set(union_temp[0]) # 1\n",
    "    B = set(union_temp[1]) # 2\n",
    "    C = A.union(B)\n",
    "    for i in range(2, len(union_temp)):\n",
    "        A = set(union_temp[i])\n",
    "        C = A.union(C)\n",
    "    print(C)\n",
    "#     print('length of union set' + str(len(C)))\n",
    "    print(f'length of union set: {len(C)}')\n",
    "    return list(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40142556",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args:\n",
    "    cols_container: fs 後的 f 集合，將每個 decomposition 後的 f 集合進行交集\n",
    "return:\n",
    "    list(C): 把交集後的結果回傳\n",
    "'''\n",
    "def Intersection(cols_container):\n",
    "    ## fs - intersection\n",
    "    print(\"-------fs-intersection-------\")\n",
    "    intersection_temp = cols_container.copy()\n",
    "    A = set(intersection_temp[0]) # 1\n",
    "    B = set(intersection_temp[1]) # 2\n",
    "    C = A.union(B)\n",
    "    for i in range(2, len(intersection_temp)):\n",
    "        A = set(intersection_temp[i])\n",
    "        C = A.intersection(C)\n",
    "    print(C)\n",
    "    print(f'length of intersection set: {len(C)}')\n",
    "    return list(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f8417",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c2125450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_clean(train_data, test_data, choosedFeature_AfterAction):\n",
    "    temp = train_data.copy()\n",
    "    del temp['class']\n",
    "    temp_selected= temp[choosedFeature_AfterAction]\n",
    "    x_train = temp_selected.sort_index(axis=1)\n",
    "#     print(x_train) #80筆資料\n",
    "\n",
    "    #把測試集手動取出與訓練集相同維度的所有資料\n",
    "    temp_test = test_data.copy() #x_test\n",
    "    del temp_test['class']\n",
    "    temp_test_selected = temp_test[choosedFeature_AfterAction]\n",
    "    x_test = temp_test_selected.sort_index(axis=1)\n",
    "#     print(x_test)\n",
    "\n",
    "    y_train = train_data['class']\n",
    "    y_test = test_data['class']\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "def train_model(x_train, x_test, y_train, y_test):\n",
    "    ## train model\n",
    "    svm.fit(x_train, y_train)\n",
    "    predicted = svm.predict(x_test)\n",
    "    \n",
    "    # accuracy_train = svm.score(x_train, y_train) #x_train, y_train\n",
    "    # print(accuracy_train)\n",
    "    accuracy_test = svm.score(x_test, y_test) #x_test, y_test\n",
    "    return accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36696584",
   "metadata": {},
   "source": [
    "## use loop 遍歷五個 training 資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "1a979663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------fs-------\n",
      "1 not  1 : ['A1', 'A3', 'A4', 'A5', 'A8', 'A9', 'A13', 'A16']\n",
      "2 not  2 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A8', 'A13']\n",
      "3 not  3 : ['A1', 'A7', 'A8', 'A9', 'A11', 'A13', 'A14', 'A16']\n",
      "4 not  4 : ['A1', 'A3', 'A4', 'A6', 'A8', 'A10', 'A12', 'A13']\n",
      "5 not  5 : ['A1', 'A6', 'A7', 'A8', 'A9', 'A10', 'A13', 'A15']\n",
      "6 not  6 : ['A3', 'A5', 'A7', 'A8', 'A9', 'A10', 'A13', 'A14']\n",
      "7 not  7 : ['A3', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A14']\n",
      "-------fs-Union-------\n",
      "{'A9', 'A16', 'A5', 'A3', 'A10', 'A15', 'A8', 'A12', 'A13', 'A14', 'A6', 'A1', 'A7', 'A11', 'A4', 'A2'}\n",
      "length of union set: 16\n",
      "accuracy of fold 1: 0.8095238095238095\n",
      "-------fs-------\n",
      "1 not  1 : ['A1', 'A3', 'A4', 'A6', 'A8', 'A10', 'A11', 'A13']\n",
      "2 not  2 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A8', 'A9', 'A13']\n",
      "3 not  3 : ['A1', 'A2', 'A3', 'A4', 'A6', 'A9', 'A10', 'A14']\n",
      "4 not  4 : ['A3', 'A4', 'A5', 'A6', 'A10', 'A12', 'A13', 'A14']\n",
      "5 not  5 : ['A1', 'A3', 'A4', 'A6', 'A9', 'A10', 'A12', 'A13']\n",
      "6 not  6 : ['A3', 'A4', 'A9', 'A10', 'A13', 'A14', 'A15', 'A16']\n",
      "7 not  7 : ['A1', 'A3', 'A5', 'A8', 'A9', 'A10', 'A11', 'A14']\n",
      "-------fs-Union-------\n",
      "{'A9', 'A16', 'A5', 'A3', 'A10', 'A15', 'A8', 'A12', 'A13', 'A14', 'A6', 'A1', 'A11', 'A4', 'A2'}\n",
      "length of union set: 15\n",
      "accuracy of fold 2: 0.9\n",
      "-------fs-------\n",
      "1 not  1 : ['A1', 'A3', 'A4', 'A8', 'A10', 'A12', 'A13', 'A16']\n",
      "2 not  2 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A8', 'A12', 'A13']\n",
      "3 not  3 : ['A1', 'A7', 'A8', 'A9', 'A10', 'A12', 'A14', 'A15']\n",
      "4 not  4 : ['A1', 'A3', 'A4', 'A6', 'A8', 'A10', 'A12', 'A13']\n",
      "5 not  5 : ['A3', 'A6', 'A8', 'A9', 'A10', 'A13', 'A14', 'A16']\n",
      "6 not  6 : ['A3', 'A4', 'A8', 'A9', 'A10', 'A13', 'A14', 'A16']\n",
      "7 not  7 : ['A1', 'A4', 'A8', 'A9', 'A13', 'A14', 'A15', 'A16']\n",
      "-------fs-Union-------\n",
      "{'A9', 'A16', 'A5', 'A10', 'A15', 'A3', 'A8', 'A12', 'A13', 'A14', 'A6', 'A1', 'A7', 'A4', 'A2'}\n",
      "length of union set: 15\n",
      "accuracy of fold 3: 0.9\n",
      "-------fs-------\n",
      "1 not  1 : ['A1', 'A3', 'A4', 'A5', 'A8', 'A9', 'A13', 'A16']\n",
      "2 not  2 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A8', 'A9', 'A13']\n",
      "3 not  3 : ['A3', 'A6', 'A7', 'A8', 'A9', 'A10', 'A14', 'A16']\n",
      "4 not  4 : ['A1', 'A3', 'A4', 'A6', 'A8', 'A10', 'A12', 'A13']\n",
      "5 not  5 : ['A2', 'A3', 'A6', 'A8', 'A9', 'A10', 'A13', 'A15']\n",
      "6 not  6 : ['A3', 'A5', 'A7', 'A8', 'A9', 'A10', 'A13', 'A14']\n",
      "7 not  7 : ['A1', 'A5', 'A6', 'A8', 'A9', 'A10', 'A14', 'A16']\n",
      "-------fs-Union-------\n",
      "{'A9', 'A16', 'A5', 'A10', 'A3', 'A15', 'A8', 'A12', 'A13', 'A14', 'A6', 'A1', 'A7', 'A4', 'A2'}\n",
      "length of union set: 15\n",
      "accuracy of fold 4: 1.0\n",
      "-------fs-------\n",
      "1 not  1 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A8', 'A13', 'A16']\n",
      "2 not  2 : ['A1', 'A2', 'A3', 'A4', 'A5', 'A8', 'A10', 'A13']\n",
      "3 not  3 : ['A3', 'A4', 'A7', 'A8', 'A9', 'A10', 'A12', 'A14']\n",
      "4 not  4 : ['A1', 'A2', 'A4', 'A6', 'A10', 'A12', 'A13', 'A14']\n",
      "5 not  5 : ['A2', 'A3', 'A6', 'A8', 'A9', 'A10', 'A13', 'A16']\n",
      "6 not  6 : ['A3', 'A4', 'A8', 'A9', 'A10', 'A13', 'A14', 'A16']\n",
      "7 not  7 : ['A3', 'A7', 'A8', 'A9', 'A10', 'A14', 'A15', 'A16']\n",
      "-------fs-Union-------\n",
      "{'A9', 'A16', 'A5', 'A10', 'A3', 'A15', 'A8', 'A12', 'A13', 'A14', 'A6', 'A1', 'A7', 'A4', 'A2'}\n",
      "length of union set: 15\n",
      "accuracy of fold 5: 1.0\n",
      "avg_acc: 0.9219047619047618\n"
     ]
    }
   ],
   "source": [
    "accuracy_container = []\n",
    "\n",
    "for i in range(5):\n",
    "    data_AfterDecomposition = decomposition(training_Data[i])\n",
    "    cols_container = []\n",
    "    cols_container_AfterFeatureSelection = featureSelection(cols_container, data_AfterDecomposition)\n",
    "    choosedFeature_AfterUnion = Union(cols_container_AfterFeatureSelection)\n",
    "    x_train_U, x_test_U, y_train_U, y_test_U = train_test_clean(training_Data[i], testing_Data[i], choosedFeature_AfterUnion)\n",
    "\n",
    "    accuracy_U = train_model(x_train_U, x_test_U, y_train_U, y_test_U)\n",
    "    accuracy_container.append(accuracy_U)\n",
    "    print(f'accuracy of fold {i+1}: {accuracy_U}')\n",
    "    \n",
    "avg_acc = sum(accuracy_container)/5\n",
    "print(f'avg_acc: {avg_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3efd64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_container_AfterFeatureSelection = featureSelection(cols_container, data_AfterDecomposition)\n",
    "# choosedFeature_AfterIntersection = Intersection(cols_container_AfterFeatureSelection)\n",
    "# x_train_I, x_test_I, y_train_I, y_test_I = train_test_clean(train_1, test_1, choosedFeature_AfterIntersection)\n",
    "# accuracy_I = train_model(x_train_I, x_test_I, y_train_I, y_test_I)\n",
    "# print(accuracy_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810038ec",
   "metadata": {},
   "source": [
    "#### 以下為原先測試版保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d947efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(data['class'].value_counts().size):\n",
    "#     data_ova = data_temp[i].copy()\n",
    "#     del data_ova['class']\n",
    "#     data_ova_no_label = data_ova.copy()\n",
    "#     del data_ova_no_label[str('class_ova_')+str(i+1)]\n",
    "#     x_reduced = selector.fit_transform(data_ova_no_label, data_ova[str('class_ova_')+str(i+1)])\n",
    "#     # x_reduced.shape\n",
    "#     cols = selector.get_support(indices=True)\n",
    "#     selected_columns = data_ova_no_label.iloc[:,cols].columns.tolist()\n",
    "#     cols_container.append(selected_columns)\n",
    "#     print(i+1,'not ', i+1, ':',selected_columns)\n",
    "# ## fs - union\n",
    "# print(\"-------fs-union-------\")\n",
    "# union_temp = cols_container.copy()\n",
    "# A = set(union_temp[0]) # 1\n",
    "# B = set(union_temp[1]) # 2\n",
    "# C = A.union(B)\n",
    "# for i in range(2, len(union_temp)):\n",
    "#     A = set(union_temp[i])\n",
    "#     C = A.union(C)\n",
    "# print(C)\n",
    "# temp = train_1.copy()\n",
    "# del temp['class']\n",
    "# temp_selected_union = temp[list(C)]\n",
    "# x_train = temp_selected_union.sort_index(axis=1)\n",
    "# print(x_train) #80筆資料\n",
    "\n",
    "# #把測試集手動取出與訓練集相同維度的所有資料\n",
    "# temp_test = test_1.copy() #x_test\n",
    "# del temp_test['class']\n",
    "# temp_test_selected_union = temp_test[list(C)]\n",
    "# x_test = temp_test_selected_union.sort_index(axis=1)\n",
    "# print(x_test)\n",
    "\n",
    "# y_train = train_1['class']\n",
    "# y_test = test_1['class']\n",
    "\n",
    "## train model\n",
    "svm.fit(x_train, y_train)\n",
    "predicted = svm.predict(x_test)\n",
    "    \n",
    "# accuracy_train = svm.score(x_train, y_train) #x_train, y_train\n",
    "# print(accuracy_train)\n",
    "accuracy_test = svm.score(x_test, y_test) #x_test, y_test\n",
    "print(accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
